#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ä» Many-Shot KV çš„ JSONL ç»“æœæ–‡ä»¶ç”Ÿæˆæ±‡æ€»è¡¨ï¼ˆæ”¯æŒä»»æ„æ¨¡å‹ï¼‰
"""
import os
import json
import csv
import numpy as np
from pathlib import Path


def analyze_jsonl_results(jsonl_path):
    """
    åˆ†æ JSONL ç»“æœæ–‡ä»¶ï¼Œæå–æ±‡æ€»æŒ‡æ ‡
    
    Args:
        jsonl_path: JSONL æ–‡ä»¶è·¯å¾„
    
    Returns:
        dict: æ±‡æ€»æŒ‡æ ‡
    """
    results = []
    
    with open(jsonl_path, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                results.append(json.loads(line))
    
    if not results:
        return None
    
    # ç»Ÿè®¡æŒ‡æ ‡
    num_shots_list = [r['num_shots'] for r in results]
    em_string_list = [r['EM_string'] for r in results]
    contains_list = [r['Contains'] for r in results]
    token_f1_list = [r['Token_F1'] for r in results]
    numeric_em_list = [r['Numeric_EM'] for r in results]
    
    # ç›¸å¯¹è¯¯å·®ï¼ˆè¿‡æ»¤ Noneï¼‰
    relerr_list = [r['rel_error'] for r in results if r['rel_error'] is not None]
    
    # æ—¶é—´å’Œ token ç»Ÿè®¡
    time_list = [r['time_spent'] for r in results]
    kv_tokens_list = [r['kv_tokens'] for r in results]
    output_tokens_list = [r['output_tokens'] for r in results]
    
    # è®¡ç®—ååé‡
    tokpersec_list = []
    for r in results:
        if r['time_spent'] > 0 and r['output_tokens'] > 0:
            tokpersec_list.append(r['output_tokens'] / r['time_spent'])
    
    summary = {
        'count': len(results),
        'num_shots_mean': float(np.mean(num_shots_list)),
        'num_shots_median': float(np.median(num_shots_list)),
        'num_shots_min': int(np.min(num_shots_list)),
        'num_shots_max': int(np.max(num_shots_list)),
        'acc_numeric': float(np.mean(numeric_em_list)),
        'em_string': float(np.mean(em_string_list)),
        'contains': float(np.mean(contains_list)),
        'token_f1': float(np.mean(token_f1_list)),
        'relerr_mean': float(np.mean(relerr_list)) if relerr_list else 0.0,
        'relerr_median': float(np.median(relerr_list)) if relerr_list else 0.0,
        'total_time_s': float(np.sum(time_list)),  # ğŸ”¥ æ–°å¢ï¼šæ€»è¿è¡Œæ—¶é—´
        'avg_latency_s': float(np.mean(time_list)),
        'avg_kv_tokens': float(np.mean(kv_tokens_list)),
        'avg_out_tokens': float(np.mean(output_tokens_list)),
        'avg_tokpersec': float(np.mean(tokpersec_list)) if tokpersec_list else 0.0
    }
    
    return summary


def parse_filename(filename):
    """
    ä»æ–‡ä»¶åè§£æé…ç½®ä¿¡æ¯
    æ”¯æŒå¤šç§æ–‡ä»¶åæ ¼å¼ï¼š
    - Qwen2.5-7B_w4_tau5.0_20251203_151042.jsonl
    - Meta-Llama-3.1-70B_w8_tau0.3_timestamp.jsonl
    - model_name_wX_tauY.Y_timestamp.jsonl
    
    Returns:
        dict: åŒ…å« model, window_size, entropy_threshold çš„å­—å…¸
    """
    parts = filename.replace('.jsonl', '').split('_')
    
    model_parts = []
    window_size = None
    entropy_threshold = None
    
    for i, part in enumerate(parts):
        if part.startswith('w') and len(part) <= 4 and part[1:].replace('.', '').isdigit():
            # çª—å£å¤§å°ï¼šw4, w8, w16 ç­‰
            if window_size is None:
                try:
                    window_size = int(part[1:])
                except:
                    pass
        elif part.startswith('tau'):
            # ç†µé˜ˆå€¼ï¼štau0.3, tau5.0 ç­‰
            try:
                entropy_threshold = float(part.replace('tau', ''))
            except:
                pass
        elif not part.isdigit() and len(part) != 8:  # æ’é™¤æ—¶é—´æˆ³
            # æ¨¡å‹åç§°éƒ¨åˆ†
            model_parts.append(part)
    
    # æ‹¼æ¥æ¨¡å‹åç§°
    model_name = '_'.join(model_parts) if model_parts else 'unknown'
    
    return {
        'model': model_name,
        'window_size': window_size or 0,
        'entropy_threshold': entropy_threshold or 0.0
    }


def infer_dataset_from_path(file_path):
    """
    ä»æ–‡ä»¶è·¯å¾„æ¨æ–­æ•°æ®é›†å’Œä»»åŠ¡ä¿¡æ¯
    
    Args:
        file_path: Path å¯¹è±¡
    
    Returns:
        tuple: (dataset_name, subset, task_name)
    """
    path_str = str(file_path).lower()
    
    # å¸¸è§æ•°æ®é›†åŒ¹é…
    dataset_mapping = {
        'gsm8k': ('openai/gsm8k', 'main'),
        'aqua': ('aqua_rat', 'raw'),
        'math500': ('math500', 'default'),
        'svamp': ('svamp', 'default'),
        'asdiv': ('asdiv', 'default'),
        'mawps': ('mawps', 'default'),
        'cot-collection': ('cot-collection', 'default'),
        'ugphysics': ('UGPhysics/ugphysics', 'mixed')
    }
    
    # ä»è·¯å¾„ä¸­æå–ä»»åŠ¡å
    task_name = 'unknown'
    # æŸ¥æ‰¾è·¯å¾„ä¸­çš„ä»»åŠ¡æ ‡è¯†ç¬¦
    import re
    # åŒ¹é…ç±»ä¼¼ llama_3.2_3b_taskname çš„æ¨¡å¼
    match = re.search(r'llama_3[._]2[._]3b[._]([^/\\]+)', path_str)
    if match:
        task_name = match.group(1)
    
    # æ ¹æ®ä»»åŠ¡åç¡®å®šæ•°æ®é›†
    dataset = 'unknown'
    subset = 'unknown'
    for key, (ds, sb) in dataset_mapping.items():
        if key in task_name:
            dataset = ds
            subset = sb
            break
    
    # å¦‚æœæ²¡æ‰¾åˆ°åŒ¹é…çš„æ•°æ®é›†ï¼Œå°è¯•ä»è·¯å¾„ä¸­æ¨æ–­
    if dataset == 'unknown':
        for key, (ds, sb) in dataset_mapping.items():
            if key in path_str:
                dataset = ds
                subset = sb
                break
    
    return dataset, subset, task_name


def generate_summary_from_manyshot_results(results_dir, output_csv, run_id='manyshot_kv'):
    """
    ä» Many-Shot KV çš„ç»“æœç›®å½•ç”Ÿæˆæ±‡æ€»è¡¨ï¼ˆæ”¯æŒä»»æ„æ¨¡å‹ï¼‰
    
    Args:
        results_dir: ç»“æœç›®å½•è·¯å¾„
        output_csv: è¾“å‡º CSV è·¯å¾„
        run_id: è¿è¡Œ ID
    """
    # æŸ¥æ‰¾æ‰€æœ‰ JSONL æ–‡ä»¶ï¼ˆæ’é™¤ probe_detailsï¼‰
    jsonl_files = [f for f in Path(results_dir).glob('**/*.jsonl') 
                   if 'probe_details' not in f.name]
    
    if not jsonl_files:
        print(f"åœ¨ {results_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½• JSONL æ–‡ä»¶")
        return
    
    print(f"æ‰¾åˆ° {len(jsonl_files)} ä¸ª JSONL æ–‡ä»¶")
    
    # CSV è¡¨å¤´
    headers = [
        "run_id", "mode", "dataset", "subset", "task_name", "model",
        "global_pool_size", "entropy_threshold", "window_size", "paper_k_full",
        "count", "optimal_k_mean", "optimal_k_median", "optimal_k_min", "optimal_k_max",
        "acc_numeric", "em_string", "contains", "token_f1",
        "acc_tol_1e-4", "acc_tol_1e-3", "acc_tol_1e-2",
        "relerr_mean", "relerr_median",
        "total_time_s", "avg_latency_s", "avg_in_tokens", "avg_out_tokens", "avg_tokpersec"  # ğŸ”¥ æ–°å¢ total_time_s
    ]
    
    all_rows = []
    
    for jsonl_file in jsonl_files:
        print(f"\nå¤„ç†: {jsonl_file.name}")
        
        # åˆ†æç»“æœ
        summary = analyze_jsonl_results(str(jsonl_file))
        if summary is None:
            print(f"  âœ— æ–‡ä»¶ä¸ºç©ºæˆ–æ— æ•ˆ")
            continue
        
        # è§£ææ–‡ä»¶å
        config = parse_filename(jsonl_file.name)
        
        # ä»è·¯å¾„æ¨æ–­æ•°æ®é›†å’Œä»»åŠ¡
        dataset, subset, task_name = infer_dataset_from_path(jsonl_file)
        
        # å°è¯•è¯»å–åŒå‰ç¼€çš„ metrics.json ä»¥è·å–çœŸå®é…ç½®
        metrics_path = str(jsonl_file).replace('.jsonl', '_metrics.json')
        metrics = None
        if os.path.exists(metrics_path):
            try:
                with open(metrics_path, 'r', encoding='utf-8') as mf:
                    metrics = json.load(mf)
            except Exception:
                metrics = None

        gp_size = 100
        win_size = config['window_size']
        tau = config['entropy_threshold']
        if metrics:
            gp_size = metrics.get('global_pool_size', gp_size)
            win_size = metrics.get('window_size', win_size)
            tau = metrics.get('entropy_threshold', tau)

        # æ„å»ºè¡Œ
        row = {
            "run_id": run_id,
            "mode": "manyshot_kv",
            "dataset": dataset,
            "subset": subset,
            "task_name": task_name,
            "model": config['model'],
            "global_pool_size": gp_size,
            "entropy_threshold": f"{float(tau):.2f}",
            "window_size": win_size,
            "paper_k_full": 0,
            "count": summary['count'],
            "optimal_k_mean": f"{summary['num_shots_mean']:.2f}",
            "optimal_k_median": f"{summary['num_shots_median']:.2f}",
            "optimal_k_min": summary['num_shots_min'],
            "optimal_k_max": summary['num_shots_max'],
            "acc_numeric": f"{summary['acc_numeric']:.4f}",
            "em_string": f"{summary['em_string']:.4f}",
            "contains": f"{summary['contains']:.4f}",
            "token_f1": f"{summary['token_f1']:.4f}",
            "acc_tol_1e-4": "0.0000",
            "acc_tol_1e-3": "0.0000",
            "acc_tol_1e-2": "0.0000",
            "relerr_mean": f"{summary['relerr_mean']:.4f}",
            "relerr_median": f"{summary['relerr_median']:.4f}",
            "total_time_s": f"{summary['total_time_s']:.2f}",  # ğŸ”¥ æ–°å¢
            "avg_latency_s": f"{summary['avg_latency_s']:.2f}",
            "avg_in_tokens": f"{summary['avg_kv_tokens']:.1f}",
            "avg_out_tokens": f"{summary['avg_out_tokens']:.1f}",
            "avg_tokpersec": f"{summary['avg_tokpersec']:.2f}"
        }
        
        all_rows.append(row)
        
        # æ‰“å°æ‘˜è¦
        print(f"  âœ“ {config['model']}")
        print(f"    å‡†ç¡®ç‡: {summary['acc_numeric']:.2%}")
        print(f"    å¹³å‡ shots: {summary['num_shots_mean']:.1f}")
        print(f"    å¹³å‡è¾“å‡º: {summary['avg_out_tokens']:.1f} tokens")
    
    # å†™å…¥ CSV
    output_path = Path(output_csv)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_csv, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=headers)
        writer.writeheader()
        for row in all_rows:
            writer.writerow(row)
    
    print(f"\nâœ“ æ±‡æ€»è¡¨å·²ç”Ÿæˆ: {output_csv}")
    print(f"  å…± {len(all_rows)} æ¡è®°å½•")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="ä» Many-Shot KV JSONL ç»“æœç”Ÿæˆæ±‡æ€»è¡¨ï¼ˆæ”¯æŒä»»æ„æ¨¡å‹ï¼‰")
    # Merge: ä¿®æ”¹é»˜è®¤è·¯å¾„ä¸ºå…±äº«å­˜å‚¨è·¯å¾„
    # Original: parser.add_argument("--results_dir", type=str, 
    # Original:                    default="./outputs",
    # Original:                    help="ç»“æœç›®å½•ï¼ˆä¼šé€’å½’æŸ¥æ‰¾æ‰€æœ‰ JSONL æ–‡ä»¶ï¼‰")
    parser.add_argument("--results_dir", type=str, 
                       default="/data/oujie/oujie-data/shareShot/AdaCache",
                       help="ç»“æœç›®å½•ï¼ˆä¼šé€’å½’æŸ¥æ‰¾æ‰€æœ‰ JSONL æ–‡ä»¶ï¼‰")
    # Merge: ä¿®æ”¹é»˜è®¤è¾“å‡ºè·¯å¾„ä¸ºå…±äº«å­˜å‚¨è·¯å¾„
    # Original: parser.add_argument("--output_csv", type=str,
    # Original:                    default="./outputs/summary_manyshot_kv.csv",
    # Original:                    help="è¾“å‡º CSV æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output_csv", type=str,
                       default="/data/oujie/oujie-data/shareShot/AdaCache/summary_manyshot_kv.csv",
                       help="è¾“å‡º CSV æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--run_id", type=str, default="manyshot_kv", help="è¿è¡Œ ID")
    
    args = parser.parse_args()
    
    generate_summary_from_manyshot_results(args.results_dir, args.output_csv, args.run_id)
