"""
Many-Shot KV Cache æ ¸å¿ƒè¯„ä¼°å™¨
æ•´åˆå®Œæ•´çš„ KV cache æ£€ç´¢ä¸å¤ç”¨æµç¨‹

å®Œæ•´æµç¨‹:
1. ç¦»çº¿ Prefilling: æ„å»º 1024-shot KV cache æ± 
2. Query ç¼–ç : æå–å¹³å‡ Q å‘é‡ qÌ„
3. Shot æ’åº: Tokençº§æ‰“åˆ† -> Shotçº§èšåˆ -> æ’åº
4. æ¢é’ˆé€‰æ‹©: æŒ‰çª—å£né€è½®æ‰©å±•ï¼Œç†µåˆ¤æ–­åœæ­¢
5. KV æ‹¼è£…: å°†é€‰ä¸­shotsçš„KVä¸prompt+queryçš„KVæ‹¼æ¥
6. æœ€ç»ˆç”Ÿæˆ: ä½¿ç”¨æ‹¼è£…çš„KV cacheç”Ÿæˆç­”æ¡ˆ
"""
import sys
import os
import json
import logging
import time
import torch
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple
from tqdm.auto import tqdm

# ä¼˜å…ˆä½¿ç”¨æœ¬åœ° AdaCache çš„è¾…åŠ©æ¨¡å—
sys.path.insert(0, os.path.dirname(__file__))
# Merge: ä¿®æ”¹è·¯å¾„ä» ../baseline åˆ° ../util
# Original: # å†åŠ å…¥ baseline è·¯å¾„ä»¥å¤ç”¨å…¶ä½™ç»„ä»¶
# Original: sys.path.insert(0, os.path.join(os.path.dirname(__file__), '../baseline'))
# åŠ å…¥æ ¹è·¯å¾„ä»¥å¤ç”¨ util åŒ…
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from util.dataset_handlers import get_dataset_handler

# å¯¼å…¥è¯„ä¼°å‡½æ•°
try:
    from util.new_metrics import evaluate_answer
except ImportError:
    from util.metrics_utils import (
        normalize_answer,
        token_f1_pair,
        parse_number_from_text,
        numeric_equal,
        relative_error
    )
    
    def evaluate_answer(pred_final: str, gold_final: str) -> dict:
        em_str = 1.0 if normalize_answer(pred_final) == normalize_answer(gold_final) else 0.0
        contains = 1.0 if normalize_answer(gold_final) in normalize_answer(pred_final) else 0.0
        tf1 = token_f1_pair(pred_final, gold_final)
        
        gold_num = parse_number_from_text(gold_final)
        pred_num = parse_number_from_text(pred_final)
        
        numeric_ok = 0
        relerr = None
        
        if gold_num is not None and pred_num is not None:
            numeric_ok = 1 if numeric_equal(pred_num, gold_num) else 0
            relerr = relative_error(pred_num, gold_num)
        
        return {
            "numeric_ok": numeric_ok,
            "relerr": relerr,
            "em_str": em_str,
            "contains": contains,
            "tf1": tf1
        }

from bm25_retriever import BM25Retriever
from kv_pool_manager import KVPoolManager
from query_encoder import QueryEncoder
from shot_ranker import ShotRanker
from probe_selector import ProbeSelector
from kv_assembler import KVAssembler
from config import AdaCacheConfig


class ManyShotKVEvaluator:
    """Many-Shot KV Cache è¯„ä¼°å™¨"""
    
    def __init__(
        self,
        model,
        tokenizer,
        config: AdaCacheConfig,
        dataset_name: str,
        dataset_subset: str = None,
        tasks: str = None,
        device: str = "npu"
    ):
        """
        åˆå§‹åŒ–è¯„ä¼°å™¨
        
        Args:
            model: è¯­è¨€æ¨¡å‹
            tokenizer: åˆ†è¯å™¨
            config: é…ç½®å¯¹è±¡
            dataset_name: æ•°æ®é›†åç§°
            dataset_subset: æ•°æ®é›†å­é›†
            tasks: ä»»åŠ¡åˆ—è¡¨
            device: è®¡ç®—è®¾å¤‡
        """
        self.model = model
        self.tokenizer = tokenizer
        self.config = config
        self.dataset_name = dataset_name
        self.dataset_subset = dataset_subset
        self.device = device
        
        # è·å–æ•°æ®é›†å¤„ç†å™¨
        self.dataset_handler = get_dataset_handler(dataset_name, dataset_subset, tasks)
        
        # åˆ›å»º BM25 æ£€ç´¢å™¨ (ç”¨äºæ„å»ºåˆå§‹ç¤ºä¾‹æ± )
        self.bm25_retriever = BM25Retriever(
            dataset_name=dataset_name,
            dataset_subset=dataset_subset,
            pool_size=config.global_pool_size,
            use_question_only=config.bm25_use_question_only,
            k1=config.bm25_k1,
            b=config.bm25_b,
            seed=config.seed,
            cache_dir=os.path.join(config.output_dir, "cache"),
            tasks=tasks
        )
        
        # åˆ›å»º KV Pool Manager
        self.kv_pool = KVPoolManager(
            model=model,
            tokenizer=tokenizer,
            dataset_handler=self.dataset_handler,
            pool_size=config.global_pool_size,
            cache_dir=os.path.join(config.output_dir, "kv_pool"),
            device=device,
            mode=config.mode  # ä¼ é€’æ¨¡å¼å‚æ•°
        )
        
        # åˆ›å»º Query Encoder
        self.query_encoder = QueryEncoder(
            model=model,
            tokenizer=tokenizer,
            device=device
        )
        
        # åˆ›å»º Shot Ranker
        self.shot_ranker = ShotRanker(
            kv_pool_manager=self.kv_pool,
            verbose=config.verbose
        )
        
        # åˆ›å»º Probe Selector
        self.probe_selector = ProbeSelector(
            model=model,
            tokenizer=tokenizer,
            kv_pool_manager=self.kv_pool,
            window_size=config.window_size,
            entropy_threshold=config.entropy_threshold,
            max_rounds=config.max_probe_rounds,
            device=device,
            verbose=config.verbose,
            mode=config.mode,  # ä¼ é€’æ¨¡å¼
            paper_num_questions=config.paper_num_questions  # ä¼ é€’ paper å‚æ•°
        )
        
        # åˆ›å»º KV Assembler
        self.kv_assembler = KVAssembler(
            model=model,
            tokenizer=tokenizer,
            kv_pool_manager=self.kv_pool,
            device=device,
            mode=config.mode,  # ä¼ é€’æ¨¡å¼
            paper_num_questions=config.paper_num_questions  # ä¼ é€’ paper å‚æ•°
        )
        
        logging.info(f"ManyShotKVEvaluator åˆå§‹åŒ–å®Œæˆ: dataset={dataset_name}/{dataset_subset}")
    
    def _get_system_prompt(self) -> str:
        """æ ¹æ®æ•°æ®é›†ç±»å‹å’Œæ¨¡å¼è·å– system prompt"""
        name_l = (self.dataset_name or "").lower()
        
        # CoT-Collection æ•°æ®é›†ï¼ˆåŒ»ç–—ã€NLI ç­‰å¤šç§ä»»åŠ¡ï¼‰
        if "cot-collection" in name_l or "modelscope" in name_l:
            if self.config.mode == "io":
                return (
                    "You are a helpful assistant. "
                    "Provide the final answer directly and clearly."
                )
            else:  # cot or paper
                return (
                    "You are a helpful assistant. "
                    "Carefully analyze the given task and provide your reasoning step by step. "
                    "Then provide the final answer clearly at the end."
                )
        
        if "aqua" in name_l:
            if self.config.mode == "io":
                return (
                    "You are a precise math assistant. "
                    "Answer multiple choice questions by providing the correct letter (A, B, C, D, or E). "
                    "End your response with 'The answer is X' where X is the correct option letter."
                )
            else:
                return (
                    "You are a precise math assistant. "
                    "Answer multiple choice questions by analyzing the options and providing the correct letter (A, B, C, D, or E). "
                    "End your response with 'The answer is X' where X is the correct option letter."
                )
        
        if "physics" in name_l:
            if self.config.mode == "io":
                return (
                    "You are a physics expert. "
                    "Provide the final numerical answer clearly."
                )
            else:
                return (
                    "You are a physics expert. "
                    "Solve the given physics problems step by step. "
                    "Provide the final numerical answer clearly at the end."
                )
        
        if "competition_math" in name_l or "math" in name_l:
            if self.config.mode == "io":
                return (
                    "You are an expert mathematician. "
                    "Provide the final answer clearly. "
                    "If applicable, use boxed{} to highlight the final answer."
                )
            else:
                return (
                    "You are an expert mathematician. "
                    "Solve the given mathematical problems step by step. "
                    "Show your work clearly and provide the final answer. "
                    "If applicable, use boxed{} to highlight the final answer."
                )
        
        if "svamp" in name_l:
            if self.config.mode == "io":
                return (
                    "You are a helpful math assistant. "
                    "Provide only the numerical answer."
                )
            else:
                return (
                    "You are a helpful math assistant. "
                    "Solve the given word problem step by step. "
                    "Provide only the numerical answer at the end."
                )
        
        # é»˜è®¤ GSM8K é£æ ¼ - å¼ºè°ƒæ­£ç¡®çš„ç­”æ¡ˆæ ¼å¼
        if self.config.mode == "io":
            return (
                "You are a precise math assistant. "
                "Provide the final answer in the format '#### <number>'. "
                "IMPORTANT: The answer must be written as '####' followed by a space and then the number. "
                "For example: '#### 42' or '#### 3.14'. "
                "Do NOT write the number before ####."
            )
        else:
            return (
                "You are a precise math assistant. "
                "Solve the given math problem step by step. "
                "IMPORTANT: End your answer with '#### <number>' where <number> is the final numerical answer. "
                "The format must be '####' followed by a space and then the number. "
                "For example: '#### 42' or '#### 3.14'. "
                "Do NOT write the number before ####."
            )
    
    def evaluate(self, test_set, output_prefix: str) -> Dict:
        """
        è¿è¡Œå®Œæ•´è¯„ä¼°
        
        Args:
            test_set: æµ‹è¯•é›†
            output_prefix: è¾“å‡ºæ–‡ä»¶å‰ç¼€
        
        Returns:
            metrics: è¯„ä¼°æŒ‡æ ‡
        """
        # ğŸ”¥ è®¾ç½® probe_selector çš„è¾“å‡ºç›®å½•ï¼ˆä¸ç»“æœæ–‡ä»¶æ”¾åœ¨åŒä¸€ç›®å½•ï¼‰
        output_dir = os.path.dirname(os.path.abspath(output_prefix))
        self.probe_selector.output_dir = output_dir
        self.probe_selector._probe_example_saved = False  # é‡ç½®æ ‡å¿—ä½
        
        # æ­¥éª¤ 1: æ„å»º BM25 ç´¢å¼•
        logging.info("=" * 80)
        logging.info("æ­¥éª¤ 1/6: æ„å»º BM25 ç´¢å¼•")
        logging.info("=" * 80)
        self.bm25_retriever.build_index()
        
        # æ­¥éª¤ 2: ç¦»çº¿ Prefilling - æ„å»º KV æ± 
        logging.info("=" * 80)
        logging.info("æ­¥éª¤ 2/6: ç¦»çº¿ Prefilling (1024-shot KV Cache æ± )")
        logging.info("=" * 80)
        pool_examples = self.bm25_retriever.pool_examples
        
        # âœ… æ„å»º Paper æ¨¡å¼çš„é…ç½®
        paper_config = None
        if self.config.mode == "paper":
            # ä½¿ç”¨å‰ 4 ä¸ª shots ä½œä¸º fullshotsï¼ˆè¿™é‡Œç®€å•ä½¿ç”¨ç¬¬ 0-3 ä¸ªï¼‰
            paper_config = {
                'fullshot_ids': list(range(4)),  # å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´
                'num_questions': self.config.paper_num_questions
            }
        
        # è·å– system prompt
        system_prompt = self._get_system_prompt()
        
        # âœ… æ„å»º KV æ± ï¼ŒåŒæ—¶ç¼“å­˜å›ºå®šéƒ¨åˆ†
        self.kv_pool.build_kv_pool(
            pool_examples,
            system_prompt=system_prompt,
            paper_config=paper_config
        )
        
        # ä¿å­˜ KV æ± ä¿¡æ¯
        kv_pool_info = self.kv_pool.get_pool_info()
        with open(f"{output_prefix}_kv_pool_info.json", 'w', encoding='utf-8') as f:
            json.dump(kv_pool_info, f, ensure_ascii=False, indent=2)
        
        # å‡†å¤‡è¾“å‡ºæ–‡ä»¶
        jsonl_path = f"{output_prefix}.jsonl"
        meta_path = f"{output_prefix}_metrics.json"
        txt_path = f"{output_prefix}_report.txt"
        probe_details_path = f"{output_prefix}_probe_details.jsonl"
        
        # æ­¥éª¤ 3-6: åœ¨çº¿è¯„ä¼°å¾ªç¯
        logging.info("=" * 80)
        logging.info("æ­¥éª¤ 3-6: åœ¨çº¿è¯„ä¼° (Queryç¼–ç  -> Shotæ’åº -> æ¢é’ˆé€‰æ‹© -> KVæ‹¼è£… -> ç”Ÿæˆ)")
        logging.info("=" * 80)
        
        n_eval = len(test_set)
        prompt_text = ""  # âœ… Prompt å·²ç»åœ¨å›ºå®šéƒ¨åˆ†äº†ï¼Œä¸éœ€è¦é‡å¤
        
        # Tokenize prompt (ç©ºæ–‡æœ¬ï¼‰
        prompt_tokens = self.tokenizer(prompt_text, return_tensors="pt").input_ids.squeeze(0)
        
        # ç»Ÿè®¡æŒ‡æ ‡
        total_em_str = 0.0
        total_contains = 0.0
        total_token_f1 = 0.0
        n_numeric_ok = 0
        total_relerr = []
        total_latency = []
        total_in_tok = []
        total_out_tok = []
        num_shots_list = []
        
        iterator = tqdm(range(n_eval), total=n_eval, desc="Many-Shot KV è¯„ä¼°")
        
        with open(jsonl_path, "w", encoding="utf-8") as fout, \
             open(probe_details_path, "w", encoding="utf-8") as fprobe:
            
            for i in iterator:
                ex = test_set[i]
                q, ref = self.dataset_handler.format_example_cot(ex)
                gold_final = self.dataset_handler.extract_gold_answer(ex)
                
                # Tokenize query
                query_tokens = self.tokenizer(q, return_tensors="pt").input_ids.squeeze(0)
                
                t_start = time.time()
                
                # æ­¥éª¤ 3: Query ç¼–ç 
                query_repr = self.query_encoder.encode_query(prompt_tokens, query_tokens)
                
                # æ­¥éª¤ 4: Shot æ’åº
                ranked_shots = self.shot_ranker.rank_shots(query_repr)
                
                # æ­¥éª¤ 5: æ¢é’ˆé€‰æ‹©
                selected_shots, probe_history = self.probe_selector.select_shots_with_probe(
                    ranked_shots, prompt_tokens, query_tokens, q  # ä¼ é€’ query æ–‡æœ¬
                )
                
                num_shots = len(selected_shots)
                num_shots_list.append(num_shots)
                
                # ä¿å­˜æ¢é’ˆè¯¦æƒ…
                fprobe.write(json.dumps({
                    "question_idx": i,
                    "question": q[:200],
                    "num_selected_shots": num_shots,
                    "probe_history": probe_history
                }, ensure_ascii=False) + "\n")
                
                # æ­¥éª¤ 6: KV æ‹¼è£…ä¸ç”Ÿæˆ
                response, gen_info = self.kv_assembler.generate_with_kv_cache(
                    selected_shots, prompt_tokens, query_tokens,
                    max_new_tokens=self.config.gen_tokens,
                    query_text=q  # ä¼ é€’ query æ–‡æœ¬
                )
                
                t_end = time.time()
                latency = t_end - t_start
                
                # æå–é¢„æµ‹ç­”æ¡ˆï¼ˆå«ç¨³å¥åå¤„ç†ï¼‰
                pred_final = self.dataset_handler.extract_prediction(response)
                if not pred_final or not any(ch.isdigit() for ch in pred_final):
                    import re
                    m = re.search(r"####\s*(-?\d+(?:\.\d+)?)", response)
                    if m:
                        pred_final = m.group(1)
                    else:
                        m2 = re.search(r"(?:the\s+)?answer\s+is\s*[:\s]*(-?\d+(?:\.\d+)?)", response, re.IGNORECASE)
                        if m2:
                            pred_final = m2.group(1)
                        else:
                            nums = re.findall(r"-?\d+(?:\.\d+)?", response)
                            if nums:
                                pred_final = nums[-1]
                
                # è¯„ä¼°
                compare_results = evaluate_answer(pred_final, gold_final)
                numeric_ok, relerr, em_str, contains, tf1 = (
                    compare_results["numeric_ok"],
                    compare_results["relerr"],
                    compare_results["em_str"],
                    compare_results["contains"],
                    compare_results["tf1"]
                )
                
                # è®°å½•
                record = {
                    "question": q,
                    "reference_answer": ref,
                    "gold_answer": gold_final,
                    "model_output": response,
                    "pred_answer": pred_final,
                    "num_shots": num_shots,
                    "selected_shot_ids": selected_shots,
                    "EM_string": em_str,
                    "Contains": contains,
                    "Token_F1": tf1,
                    "Numeric_EM": numeric_ok,
                    "rel_error": relerr,
                    "time_spent": latency,
                    "kv_tokens": gen_info['total_kv_tokens'],
                    "output_tokens": gen_info['output_tokens']
                }
                fout.write(json.dumps(record, ensure_ascii=False) + "\n")
                
                # ç´¯è®¡
                total_em_str += em_str
                total_contains += contains
                total_token_f1 += tf1
                n_numeric_ok += numeric_ok
                if relerr is not None:
                    total_relerr.append(relerr)
                total_latency.append(latency)
                total_in_tok.append(gen_info['total_kv_tokens'])
                total_out_tok.append(gen_info['output_tokens'])
        
        # è®¡ç®—æ±‡æ€»æŒ‡æ ‡
        logging.info("=" * 80)
        logging.info("æ±‡æ€»è¯„ä¼°ç»“æœ")
        logging.info("=" * 80)
        
        count = n_eval
        relerr_mean = float(np.mean(total_relerr)) if total_relerr else 0.0
        relerr_median = float(np.median(total_relerr)) if total_relerr else 0.0
        
        acc_numeric = n_numeric_ok / count if count else 0.0
        
        meta = {
            "dataset": f"{self.dataset_name}/{self.dataset_subset}",
            "count": count,
            "mode": f"manyshot_kv_cache_{self.config.mode}",  # æ·»åŠ æ¨¡å¼ä¿¡æ¯
            "global_pool_size": self.config.global_pool_size,
            "window_size": self.config.window_size,
            "entropy_threshold": self.config.entropy_threshold,
            "num_shots_mean": float(np.mean(num_shots_list)),
            "num_shots_median": float(np.median(num_shots_list)),
            "num_shots_min": int(np.min(num_shots_list)),
            "num_shots_max": int(np.max(num_shots_list)),
            "acc_numeric": acc_numeric,
            "acc_numeric_n": n_numeric_ok,
            "em_string": total_em_str / count if count else 0.0,
            "contains": total_contains / count if count else 0.0,
            "token_f1": total_token_f1 / count if count else 0.0,
            "relerr_mean": relerr_mean,
            "relerr_median": relerr_median,
            "avg_latency_s": float(np.mean(total_latency)) if total_latency else 0.0,
            "avg_kv_tokens": float(np.mean(total_in_tok)) if total_in_tok else 0.0,
            "avg_out_tokens": float(np.mean(total_out_tok)) if total_out_tok else 0.0,
        }
        
        # ä¿å­˜æŒ‡æ ‡
        with open(meta_path, "w", encoding="utf-8") as f:
            json.dump(meta, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜æ–‡æœ¬æŠ¥å‘Š
        with open(txt_path, "w", encoding="utf-8") as f:
            f.write("=" * 80 + "\n")
            f.write("Many-Shot KV Cache è¯„ä¼°æŠ¥å‘Š\n")
            f.write("=" * 80 + "\n\n")
            f.write(f"æ•°æ®é›†: {meta['dataset']}\n")
            f.write(f"æµ‹è¯•æ ·æœ¬æ•°: {count}\n")
            f.write(f"å…¨å±€ç¤ºä¾‹æ± : {meta['global_pool_size']}\n")
            f.write(f"çª—å£å¤§å°: {meta['window_size']}\n")
            f.write(f"ç†µé˜ˆå€¼: {meta['entropy_threshold']}\n\n")
            
            f.write("=" * 80 + "\n")
            f.write("Shot æ•°é‡ç»Ÿè®¡\n")
            f.write("=" * 80 + "\n")
            f.write(f"å¹³å‡: {meta['num_shots_mean']:.2f}\n")
            f.write(f"ä¸­ä½æ•°: {meta['num_shots_median']:.1f}\n")
            f.write(f"èŒƒå›´: [{meta['num_shots_min']}, {meta['num_shots_max']}]\n\n")
            
            f.write("=" * 80 + "\n")
            f.write("å‡†ç¡®ç‡æŒ‡æ ‡\n")
            f.write("=" * 80 + "\n")
            f.write(f"Acc (Numeric-EM): {meta['acc_numeric']:.4f} ({meta['acc_numeric_n']}/{count})\n")
            f.write(f"EM (String): {meta['em_string']:.4f}\n")
            f.write(f"Contains: {meta['contains']:.4f}\n")
            f.write(f"Token-F1: {meta['token_f1']:.4f}\n\n")
            
            f.write("=" * 80 + "\n")
            f.write("æ€§èƒ½æŒ‡æ ‡\n")
            f.write("=" * 80 + "\n")
            f.write(f"å¹³å‡å»¶è¿Ÿ: {meta['avg_latency_s']:.3f} s\n")
            f.write(f"å¹³å‡ KV tokens: {meta['avg_kv_tokens']:.1f}\n")
            f.write(f"å¹³å‡è¾“å‡º tokens: {meta['avg_out_tokens']:.1f}\n")
        
        logging.info(f"âœ“ è¯„ä¼°å®Œæˆï¼å‡†ç¡®ç‡: {meta['acc_numeric']:.4f}, å¹³å‡shots: {meta['num_shots_mean']:.2f}")
        
        return meta
